{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "\n",
    "def get_prediction(model, tokenizer, text, entity_types, predicates):\n",
    "\n",
    "    input_format = \"\"\"Perform Named Entity Recognition (NER) and extract knowledge graph triplets from the text. NER identifies named entities of given entity types, and triple extraction identifies relationships between entities using specified predicates.\n",
    "      \n",
    "        **Entity Types:**\n",
    "        {entity_types}\n",
    "        \n",
    "        **Predicates:**\n",
    "        {predicates}\n",
    "        \n",
    "        **Text:**\n",
    "        {text}\n",
    "        \"\"\"\n",
    "\n",
    "    message = input_format.format(\n",
    "                entity_types = json.dumps({\"entity_types\": entity_types}),\n",
    "                predicates = json.dumps({\"predicates\": predicates}),\n",
    "                text = text)\n",
    "\n",
    "    messages = [{'role': 'user', 'content': message}]\n",
    "    input_ids = tokenizer.apply_chat_template(messages, add_generation_prompt = True, return_tensors=\"pt\").to(\"cpu\")\n",
    "    output = tokenizer.decode(model.generate(input_ids=input_ids, max_length=2048)[0], skip_special_tokens=True)\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "def extract_json_from_string(input_string: str) -> dict:\n",
    "    # extract the JSON part from the string\n",
    "    json_match = re.search(r'```json\\s*(\\{.*\\})\\s*```', input_string, re.DOTALL)\n",
    "    \n",
    "    if json_match:\n",
    "        json_str = json_match.group(1)\n",
    "        try:\n",
    "            json_data = json.loads(json_str)\n",
    "            return json_data\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error decoding JSON: {e}\")\n",
    "            return None\n",
    "    else:\n",
    "        print(\"No JSON found in the string.\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entity_dict(string_list):\n",
    "    result = {}\n",
    "    for string in string_list:\n",
    "        # Check if there's exactly one pair of brackets in the string\n",
    "        if string.count('[') == 1 and string.count(']') == 1:\n",
    "            # Extract the content inside the brackets\n",
    "            key = string[string.find('[') + 1:string.find(']')]\n",
    "            # Extract the substring after the bracket\n",
    "            value = string[string.find(']') + 2:].strip()\n",
    "            result[key] = value\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_relation(input_string):\n",
    "    start_bracket = input_string.find('[')\n",
    "    end_bracket = input_string.find(']', start_bracket + 1)\n",
    "\n",
    "    substring = input_string[end_bracket + 1 : input_string.find('[', end_bracket + 1)]\n",
    "    cleaned_substring = substring.strip()\n",
    "    \n",
    "    return cleaned_substring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_triplets(input_string, entity_dict):\n",
    "\n",
    "    relation = extract_relation(input_string)\n",
    "    keys = re.findall(r'\\[(\\d+)\\]', input_string)\n",
    "    nodes = [entity_dict[key] for key in keys if key in entity_dict]\n",
    "    subject = nodes[0].split(':')[0]\n",
    "    subject_type = nodes[0].split(':')[1]\n",
    "    object = nodes[1].split(':')[0]\n",
    "    object_type = nodes[1].split(':')[1]\n",
    "    \n",
    "    return [subject, subject_type, relation, object, object_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_triplets(prediction):\n",
    "    triplets = []\n",
    "    entities_and_triplets = extract_json_from_string(prediction)\n",
    "    entity_dict = get_entity_dict(entities_and_triplets['entities_and_triples'])\n",
    "    \n",
    "    for entity_triplet_string in entities_and_triplets['entities_and_triples']:\n",
    "        if entity_triplet_string.count('[') == 2 and entity_triplet_string.count(']') == 2:\n",
    "            triplet = extract_triplets(entity_triplet_string, entity_dict)\n",
    "            triplets.append(triplet)\n",
    "    return triplets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"sciphi/triplex\", trust_remote_code=True).to('cpu').eval()\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sciphi/triplex\", trust_remote_code=True)\n",
    "entity_types = [ \"Government Body\", \"Regulatory Body\", \"PERSON\", \"Geopolitical Entity\", \"COMPANY\", \"PRODUCT\", \"EVENT\", \"SECTOR\", \"ECON_INDICATOR\", \"CONCEPT\"]\n",
    "predicates = [ \"Has\", \"Announce\", \"Operate_In\", \"Introduce\", \"Produce\", \"Control\", \"Participates_In\", \"Impact\", \"Positive_Impact_On\", \"Negative_Impact_On\", \"Relate_To\", \"Is_Member_Of\", \"Invests_In\", \"Raise\", \"Decrease\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "header = [\"id\", \"subject\", \"subject_type\", \"relation\", \"object\", \"object_type\", \"input\", \"wiki_page\"]\n",
    "output_filename = \"data/triplex_knowledge_extraction.csv\"\n",
    "input_file_path = 'data/mistral_knowledge_extraction.csv'\n",
    "\n",
    "with open(input_file_path, mode='r') as input_file:\n",
    "    with open(output_filename, mode='w', newline='') as output_file:\n",
    "        writer = csv.writer(output_file)\n",
    "        writer.writerow(header)\n",
    "        reader = csv.DictReader(input_file)\n",
    "        \n",
    "        previous_id = None\n",
    "        for row in reader:\n",
    "            current_id = row['id']\n",
    "            if current_id != previous_id:\n",
    "                print(row['id'])\n",
    "                text = row['input']\n",
    "                prediction = get_prediction(model, tokenizer, text, entity_types, predicates)\n",
    "                try:\n",
    "                    triplets = get_triplets(prediction)\n",
    "                except:\n",
    "                    print(\"Error: \" + str(current_id))\n",
    "                    previous_id = current_id\n",
    "                    continue\n",
    "                for triplet in triplets:\n",
    "                    triplet.insert(0, row['id'])\n",
    "                    triplet.append(row['input'])\n",
    "                    triplet.append(\"\")\n",
    "                    writer.writerow(triplet)\n",
    "            previous_id = current_id\n",
    "      \n",
    "\n",
    "print(f\"CSV file '{output_file}' has been created successfully.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "evaluation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
